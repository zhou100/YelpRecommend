{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Challenge - NLP\n",
    "\n",
    "BitTiger DS501\n",
    "\n",
    "Jun 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "○\tLoad, visualize data\n",
    "\n",
    "○\tDefine positive/negative reviews\n",
    "\n",
    "○\tExtract Tf-Idf feature vectors from review data\n",
    "\n",
    "○\tBuild review classifiers using supervised ML models\n",
    "\n",
    "○\tUse cross-validation and grid search to tune parameters and select models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data/last_2_years_restaurant_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>Steakhouses, Restaurants, Cajun/Creole</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>0</td>\n",
       "      <td>VETXTwMw6qxzOVDlXfe6Tg</td>\n",
       "      <td>5</td>\n",
       "      <td>went for dinner tonight. Amazing my husband ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>ymlnR8UeFvB4FZL56tCZsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>Steakhouses, Restaurants, Cajun/Creole</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-04</td>\n",
       "      <td>0</td>\n",
       "      <td>S8-8uZ7fa5YbjnEtaW15ng</td>\n",
       "      <td>5</td>\n",
       "      <td>This was an amazing dinning experience! ORDER ...</td>\n",
       "      <td>0</td>\n",
       "      <td>9pSSL6X6lFpY3FCRLEH3og</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>Steakhouses, Restaurants, Cajun/Creole</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-22</td>\n",
       "      <td>1</td>\n",
       "      <td>1nK5w0VNfDlnR3bOz13dJQ</td>\n",
       "      <td>5</td>\n",
       "      <td>My husband and I went there for lunch on a Sat...</td>\n",
       "      <td>1</td>\n",
       "      <td>gm8nNoA3uB4In5o_Hxpq3g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>Steakhouses, Restaurants, Cajun/Creole</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>0</td>\n",
       "      <td>N1Z93BthdJ7FT2p5S22jIA</td>\n",
       "      <td>3</td>\n",
       "      <td>Went for a nice anniversary dinner. Researched...</td>\n",
       "      <td>0</td>\n",
       "      <td>CEtidlXNyQzgJSdF1ubPFw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>Steakhouses, Restaurants, Cajun/Creole</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>_Uwp6FO1X-avE9wqTMC59w</td>\n",
       "      <td>5</td>\n",
       "      <td>This place is first class in every way. Lobste...</td>\n",
       "      <td>0</td>\n",
       "      <td>-Z7Nw2UF7NiBSAzfXNA_XA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                  name  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "\n",
       "                               categories  avg_stars  cool        date  funny  \\\n",
       "0  Steakhouses, Restaurants, Cajun/Creole        4.0     0  2017-02-14      0   \n",
       "1  Steakhouses, Restaurants, Cajun/Creole        4.0     0  2017-12-04      0   \n",
       "2  Steakhouses, Restaurants, Cajun/Creole        4.0     0  2016-08-22      1   \n",
       "3  Steakhouses, Restaurants, Cajun/Creole        4.0     0  2016-09-13      0   \n",
       "4  Steakhouses, Restaurants, Cajun/Creole        4.0     0  2015-02-02      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  VETXTwMw6qxzOVDlXfe6Tg      5   \n",
       "1  S8-8uZ7fa5YbjnEtaW15ng      5   \n",
       "2  1nK5w0VNfDlnR3bOz13dJQ      5   \n",
       "3  N1Z93BthdJ7FT2p5S22jIA      3   \n",
       "4  _Uwp6FO1X-avE9wqTMC59w      5   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  went for dinner tonight. Amazing my husband ha...       0   \n",
       "1  This was an amazing dinning experience! ORDER ...       0   \n",
       "2  My husband and I went there for lunch on a Sat...       1   \n",
       "3  Went for a nice anniversary dinner. Researched...       0   \n",
       "4  This place is first class in every way. Lobste...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  ymlnR8UeFvB4FZL56tCZsA  \n",
       "1  9pSSL6X6lFpY3FCRLEH3og  \n",
       "2  gm8nNoA3uB4In5o_Hxpq3g  \n",
       "3  CEtidlXNyQzgJSdF1ubPFw  \n",
       "4  -Z7Nw2UF7NiBSAzfXNA_XA  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your feature variables, here is the text of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the values of the column that contains review text data, save to a variable named \"documents\"\n",
    "documents = df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"went for dinner tonight. Amazing my husband had lobster bisque and the T bone both were delish.I had the French onion soup and the pan seared duck. Cooked to perfection and I'm still raving about the flavor. If you are ever in Vegas this is a must try.\",\n",
       "       'This was an amazing dinning experience! ORDER THE PORK CHOP! I will definitely return.',\n",
       "       \"My husband and I went there for lunch on a Saturday. We had a physically exhausting week so we decided to treat ourselves. But it hasn't always been easy for our allergy whenever we ate out. So we called Delmonico ahead to see if they can accommodate our special needs. The lady who answered our call was very courteous and we felt comfortable to try after having some answers from her.\\r\\nAs we arrived, the restaurant has a comfortable ambience. I wouldn't say it is grand or special but just comfortable. When it was time to order, the server was courteous regarding our allergy too and I believe the one who took care of us was a manager. He even checked with the chef to make sure the complimentary popover was okay for us to consume. We told them we are allergic to soy, corn, peanut, tomato and pork products, and some other stuff, and he had been very mindful and advised accordingly as we ordered, he did it so graciously that we didn't feel being put in a spot. Some other semi high end restaurants had given us a startled face or even an uncomfortable face when we mentioned our allergy, but this manager was super professional that he didn't make us feel crappy about our differences from others. So he made a potential stressful situation easy for us, very impressive.\\r\\nTheir steak was aged in house by the restaurant and we think their aging was done fabulously as there was no rotten smell or taste in it. The manager even double checked with us and informed us that the beef was sourced from corn fed cows and asked if we would be able to tolerate that. And we made our decision to say yes and went ahead with the steak. Their steaks were very delicious. We actually asked for medium well with no seasoning and the steak still came out super delicious and juicy. So the good quality is in the steak itself and didn't need to depend on seasoning or being served bloodily. Again, very impressive.\\r\\nAnyway, it was a delicious meal and we were well taken care of so we didn't get sick from any event of undisclosed allergens. We are very happy with this meal. We would go back when we have another time wanting to treat ourselves again. Hopefully the manager will be there again the next time we visit.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect your documents, e.g. check the size, take a peek at elements of the numpy array\n",
    "documents[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your target variable (any categorical variable that may be meaningful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For example, I am interested in perfect (5 stars) and imperfect (1-4 stars) rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a column and take the values, save to a variable named \"target\"\n",
    "df['favorable'] = df['stars']>4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You may want to look at the statistic of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be implemented\n",
    "target = df['favorable'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4741461922405801"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create training dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents is your X, target is your y\n",
    "# Now split the data to training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to documents_train, documents_test, target_train, target_test\n",
    "documents_train, documents_test, target_train, target_test = train_test_split(\n",
    "    documents, target, test_size = 0.95, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get NLP representation of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer, and name it vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english',max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with your training data\n",
    "vectors_train = vectorizer.fit_transform(documents_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocab of your tfidf\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to transform your test data\n",
    "vectors_test = vectorizer.transform(documents_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar review search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# We will need these helper methods pretty soon\n",
    "\n",
    "def get_top_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the highest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"cat\", \"pig\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[::-1][:n]]  # np.argsort by default sorts values in ascending order\n",
    "\n",
    "def get_bottom_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the lowest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"mouse\", \"rabbit\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[:n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Really dig this joint. The first time I was here, I was a bit confused as far as ordering food and pizza from separate places. It was crowded but it did not take long to get our order of pizza and wings. I've been several times since and have been very satisfied with the atmosphere and the people. I would recommend to anyone who wants a chill drinking spot.\n",
      "[\"Really dig this joint. The first time I was here, I was a bit confused as far as ordering food and pizza from separate places. It was crowded but it did not take long to get our order of pizza and wings. I've been several times since and have been very satisfied with the atmosphere and the people. I would recommend to anyone who wants a chill drinking spot.\"]\n"
     ]
    }
   ],
   "source": [
    "# Draw an arbitrary review from test (unseen in training) documents\n",
    "search_query = documents_test[55]\n",
    "search_queries = [search_query]\n",
    "print(search_query)\n",
    "print(search_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the drawn review(s) to vector(s)\n",
    "vectors_search_queries = vectorizer.transform(search_queries).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity score(s) between vector(s) and training vectors\n",
    "similarity_scores= cosine_similarity(vectors_search_queries,vectors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find top 5 similar reviews\n",
    "n = 5\n",
    "top5_review= get_top_values(similarity_scores[0],n,documents_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our search query:\n",
      "Really dig this joint. The first time I was here, I was a bit confused as far as ordering food and pizza from separate places. It was crowded but it did not take long to get our order of pizza and wings. I've been several times since and have been very satisfied with the atmosphere and the people. I would recommend to anyone who wants a chill drinking spot.\n"
     ]
    }
   ],
   "source": [
    "print('Our search query:')\n",
    "print(search_queries[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most 5 similar reviews:\n",
      "#0:\n",
      "Boom dot com! I've had the pizza, wings, fingers and fries; everything is incredibly delicious most definitely my new favorite pizza joint\n",
      "============================================================\n",
      "#1:\n",
      "Two stars for the naked chicken wings because those were good. I thought i'd try something new by ordering the Skinny Up pizza this time. The description did say that it would be less...smaller portions. I had no idea it would be so minimalistic! It barely had anything on it. On top of that it was scorched! Thinnest pizza ever. Like cardboard. Super dissapointing. Never ordering this pizza ever again.\n",
      "============================================================\n",
      "#2:\n",
      "I rarely eat pizza, so I gave in to ordering through the phone App because I was too lazy to go out and get a real pizza.  So basically I got what I deserved...a nasty, under cooked pizza.  I usually order from Domino's, but recalled Pizza Hut being better.  I was wrong!  Next time I'm lazy and want a cheap pizza, I won't be ordering here.  \r\n",
      "\r\n",
      "It's definitely quick service and the driver was nice, but that's about it.  The phone App is horrible.  I had to try several times to get my order in the cart correctly because it would take me to a web page and then clear my order.  That was my first warning sign, but I chose to ignore it.  The pizza toppings are carelessly spread throughout the pizza and the dough is under cooked and not even crunchy.\r\n",
      "\r\n",
      "I did order the dessert brownie.  That was the only thing that was decent.\n",
      "============================================================\n",
      "#3:\n",
      "I love Pizza and I loved my experience at Bruno's Pizza!\r\n",
      "\r\n",
      "I am so over commercial pizza places like pizza hut & dominio's so I had to search for a hand crafted pizza place. Bruno's Pizza most defiantly deliver on my order. I ordered a large meat lovers pizza, buffalo wings, and received two free garlic breads, and EVERYTHING WAS DELICIOUS.\r\n",
      "\r\n",
      "When ordering my pizza the staff was nice and friendly, and very helpful. The inside of this establishment is pretty small. They have a few chairs and tables sat up if you want to eat, but I think I would just order take out. If Bruno's pizza would add a few TV's & have Sunday football beer specials. I would love to come here enjoy yummy pizza and watch the game, but I will defiantly be back.\r\n",
      "\r\n",
      "Thank Bruno for the yummy Pizza!!\n",
      "============================================================\n",
      "#4:\n",
      "My go to pizza joint when I am in Vegas. Best if you order a whole fresh made pizza than by the slice.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print('Most %s similar reviews:' % n)\n",
    "for i, review in enumerate(top5_review):\n",
    "    print('#%s:' % i) \n",
    "    print(review) \n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying positive/negative review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Naive-Bayes Classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model_nb = MultinomialNB()\n",
    "\n",
    "model_nb.fit(vectors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8010301233026378"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_nb.score(vectors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7962650509378445"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model_nb.score(vectors_test,target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Logistic Regression Classifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "\n",
    "model_lr.fit(vectors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8279381926018418"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_lr.score(vectors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8132952620658044"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model_lr.score(vectors_test,target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####key features(words) that make the positive prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazing',\n",
       " 'best',\n",
       " 'perfect',\n",
       " 'fantastic',\n",
       " 'awesome',\n",
       " 'delicious',\n",
       " 'excellent',\n",
       " 'favorite',\n",
       " 'outstanding',\n",
       " 'incredible',\n",
       " 'great',\n",
       " 'love',\n",
       " 'thank',\n",
       " 'phenomenal',\n",
       " 'gem',\n",
       " 'die',\n",
       " 'greeted',\n",
       " 'owner',\n",
       " 'fabulous',\n",
       " 'wonderful']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find it out by ranking\n",
    "n = 20 \n",
    "get_top_values(model_lr.coef_[0],n,words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define good: amazing',\n",
    " 'best',\n",
    " 'perfect',\n",
    " 'fantastic',\n",
    " 'awesome',\n",
    " 'delicious',\n",
    " 'excellent', "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What are the key features(words) that make the negative prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worst',\n",
       " 'ok',\n",
       " 'horrible',\n",
       " 'rude',\n",
       " 'mediocre',\n",
       " 'slow',\n",
       " 'terrible',\n",
       " 'overpriced',\n",
       " 'bland',\n",
       " 'disappointing',\n",
       " 'average',\n",
       " 'decent',\n",
       " 'unfortunately',\n",
       " 'okay',\n",
       " 'dry',\n",
       " 'reason',\n",
       " 'wasn',\n",
       " 'overall',\n",
       " 'worse',\n",
       " 'lacking']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find it out by ranking\n",
    "n = 20\n",
    "get_bottom_values(model_lr.coef_[0],n,words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define terrible: overpriced, rude, slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=10, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "model_rfc = RandomForestClassifier(min_samples_leaf=10, n_estimators = 5)\n",
    "\n",
    "model_rfc.fit(vectors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8199157171843297"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_rfc.score(vectors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7625085635708571"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model_rfc.score(vectors_test,target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the training score and the test score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "worse than logistic regression and naive bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what features (words) are important by inspecting the RFC model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazing',\n",
       " 'delicious',\n",
       " 'best',\n",
       " 'great',\n",
       " 'minutes',\n",
       " 'love',\n",
       " 'wasn',\n",
       " 'like',\n",
       " 'awesome',\n",
       " 'favorite',\n",
       " 'vegas',\n",
       " 'place',\n",
       " 'friendly',\n",
       " 'good',\n",
       " 'excellent',\n",
       " 'didn',\n",
       " 'bad',\n",
       " 'ok',\n",
       " 'definitely',\n",
       " 'perfect']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 20\n",
    "get_top_values(model_rfc.feature_importances_,n,words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Use cross validation to evaluate classifiers\n",
    "\n",
    "[sklearn cross validation](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To be implemented\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use grid search to find best predictable classifier\n",
    "\n",
    "\n",
    "[sklearn grid search tutorial (with cross validation)](http://scikit-learn.org/stable/modules/grid_search.html#grid-search)\n",
    "\n",
    "[sklearn grid search documentation (with cross validation)](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To be implemented\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
